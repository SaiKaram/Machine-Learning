{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Dec 19 12:56:04 2017\n",
    "\n",
    "@author: karam\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def cost_function(X, y, theata):\n",
    "    \"\"\" computes the cost of using theta as the parameter \n",
    "    for linear regression to fit the data points in X and y\n",
    "    \"\"\"\n",
    "\n",
    "    m = len(y) \n",
    "    J = np.sum((X.dot(theata)-y)**2)/2/m\n",
    "    \n",
    "    return J\n",
    "\n",
    "\n",
    "def gradient_descent(X, y, theata,theataOld,alpha, epsilon):\n",
    "    \"\"\"\n",
    "    gradient_descent Performs gradient descent to learn theta\n",
    "    \"\"\"\n",
    "    \n",
    "    while (np.linalg.norm(theata - theataOld,ord = 2)) >= epsilon:\n",
    "        hypothesis = X.dot(theata)\n",
    "        loss = hypothesis-y\n",
    "        theataOld = theata\n",
    "        gradient = X.T.dot(loss)/len(y)\n",
    "        theata = theata - alpha*gradient\n",
    "        cost = cost_function(X, y, theata)\n",
    "\n",
    "    return theata\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#main function\n",
    "\n",
    "#Initializing theata\n",
    "theata = np.ones(14)\n",
    "theata = np.reshape(theata,(14,1))\n",
    "theataOld= 9999 * theata\n",
    "\n",
    "# Load the Boston housing dataset\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train = np.insert(X_train,0,1,axis=1)\n",
    "X_test = np.insert(X_test,0,1,axis=1)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_train = np.reshape(y_train,(404,1))\n",
    "y_test = np.array(y_test)\n",
    "y_test = np.reshape(y_test,(102,1))\n",
    "\n",
    "#Error Tolerance\n",
    "epsilon = 0.0000001\n",
    "\n",
    "#Learning Rate\n",
    "alpha = 1e-3\n",
    "\n",
    "#Finding Optimum theatas\n",
    "optimum_theata = gradient_descent(X_train,y_train,theata,theataOld,alpha,epsilon)\n",
    "\n",
    "\n",
    "\n",
    "Y_predict = X_test.dot(optimum_theata)\n",
    "print metrics.mean_squared_error(y_test,Y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
